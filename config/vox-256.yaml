# 在深度学习网络中,.yaml文件通常被用来定义模型的架构、超参数、数据预处理方式等配置信息.
# 这些配置信息可以被用于训练模型、评估模型性能、调整模型超参数等.
# 在模型架构的定义中,.yaml文件通常包括模型的各个层的类型、参数和超参数的设置,
# 如卷积神经网络的卷积层、池化层、全连接层等.
# 在超参数的定义中,.yaml文件通常包括学习率、优化器类型、正则化方法、训练批次大小等.
# 在数据预处理的定义中,.yaml文件通常包括对输入数据进行预处理的方式,如归一化、标准化、随机翻转等.
# 使用.yaml文件进行配置可以使得配置信息更加清晰、易于管理和维护.
# 另外,许多深度学习框架,如PyTorch、TensorFlow等,都提供了支持.yaml文件的配置方式,
# 这使得用户可以方便地在不同的深度学习框架之间进行转换和迁移.

# dataset_params通常指用于配置数据集参数的一组配置项.
# 这些配置项可以被用于构建数据加载器,从而将数据集导入深度学习模型中进行训练和评估.
# 使用dataset_params配置数据集参数可以使得数据集的处理更加灵活和方便,
# 同时也可以避免在代码中硬编码数据集路径和参数等信息,从而使得代码更加易于维护和复用.
dataset_params:
  # 数据集路径
  root_dir: /zlh/VoxCeleb/first-order-256
  # 在视频处理中,frame_shape通常是一个包含三个元素的元组,
  # 即(frame_height, frame_width, num_channels).
  # 其中,frame_height和frame_width分别表示每个帧的高度和宽度,
  # num_channels表示每个帧的颜色通道数.
  # 例如,如果每个帧的高度为256像素,宽度为256像素,且颜色通道数为3,则可以表示为(256, 256, 3).
  frame_shape: [ 256, 256, 3 ]
  # 在深度学习中,id_sampling为True表示对数据进行采样.
  # 具体来说,如果id_sampling为True,则会在训练过程中随机选择一部分数据进行训练,
  # 而不是使用所有的训练数据进行训练.
  id_sampling: True
  # 在深度学习中,如果pairs_list为None,则通常表示使用原始数据集进行训练,而不是使用配对数据进行训练.
  # 这种情况适用于一些常见的深度学习任务,例如图像分类、目标检测等.
  # 在这些任务中,输入数据通常是一组独立的图像或文本,而目标输出则是每个图像或文本的类别标签、边界框、序列等.
  # 此时训练数据集通常由一组独立的输入和目标输出数据组成,例如一组图像和相应的标签.
  # 在训练过程中,模型将使用每个输入数据来生成预测输出,然后与目标输出进行比较以计算损失,并更新模型参数.
  pairs_list: None
  # 在深度学习中,augmentation_params通常指用于数据增强的参数配置.
  # 数据增强是一种常用的技术,它通过对训练数据进行变换和扰动来生成更多的训练样本,以增强模型的鲁棒性和泛化能力.
  augmentation_params:
    # 在深度学习中,flip_param通常指用于图像翻转的参数配置.
    # 图像翻转是一种常用的数据增强方法,它可以将输入图像在水平或垂直方向上进行翻转,
    # 从而生成更多的训练样本,以增强模型的鲁棒性和泛化能力.
    flip_param:
      # 其中horizontal_flip和time_flip分别控制图像是否进行水平和时间维度上的翻转,
      # 如果设置为True,则表示进行翻转,否则不进行翻转.
      # 具体来说,horizontal_flip控制图像在水平方向上进行翻转,可以增加数据集的多样性,
      # 避免模型对物体在水平方向上的偏差感知.time_flip控制数据在时间维度上进行翻转,
      # 主要应用于视频类数据,可以增加数据集的多样性,避免模型对时间方向上的偏差感知.
      # 需要注意的是,在设置翻转参数时,需要根据具体的数据集和模型来选择合适的翻转方式和程度,
      # 避免数据失真和信息丢失,以获得最佳的训练效果.
      horizontal_flip: True
      time_flip: True
    # 这段代码表示图像增强中的颜色抖动参数配置,其中jitter_param包含了4个子参数,
    # 分别是brightness、contrast、saturation和hue,
    # 用于控制图像在亮度、对比度、饱和度和色调方面的变化程度.
    # 具体来说:
    # brightness用于控制图像亮度的变化程度,取值范围一般为[0, 1],数值越大表示亮度变化越明显；
    # contrast用于控制图像对比度的变化程度,取值范围也为[0, 1],数值越大表示对比度变化越明显；
    # saturation用于控制图像饱和度的变化程度,取值范围同样为[0, 1],数值越大表示饱和度变化越明显；
    # hue用于控制图像色调的变化程度,取值范围为[-0.5, 0.5],数值越大表示色调变化越明显.
    # 需要注意的是,在设置颜色抖动参数时,需要根据具体的数据集和模型来选择合适的参数取值,
    # 避免数据失真和信息丢失,以获得最佳的训练效果.
    # 同时,也可以结合其他的数据增强方法,如图像翻转、旋转、裁剪等,以获得更丰富和有效的训练样本.
    jitter_param:
      brightness: 0.1
      contrast: 0.1
      saturation: 0.1
      hue: 0.1

# model_params是一个用于指定模型超参数和配置的部分,
# 包括模型的类型、层数、通道数、卷积核大小、池化方式、正则化方式等等.
# 在深度学习任务中,模型的超参数和配置往往对模型的性能和训练效果有着至关重要的影响.
# 具体来说,model_params中可以包含多个子参数,如model_type用于指定模型的类型,
# 常见的有卷积神经网络(CNN)、循环神经网络(RNN)和转移神经网络(Transformer)等；
# num_layers用于指定模型的层数,num_channels用于指定卷积层的输出通道数,
# kernel_size用于指定卷积核的大小,pooling_type用于指定池化方式,如最大池化或平均池化等；
# regularization_type用于指定正则化方式,如L1、L2或dropout等.
# 需要注意的是,在设置模型参数时,需要根据具体的任务和数据集来选择合适的参数取值,
# 避免模型过拟合或欠拟合,以获得最佳的训练效果和泛化性能.
# 同时,也可以结合其他的技术和方法,如迁移学习、模型融合等,进一步提高模型的性能和鲁棒性.
model_params:
  # common_params一般用于存储与模型或任务相关的通用参数配置,
  # 这些参数可以被整个模型或任务所共享,用于控制模型的整体行为和性能.
  common_params:
    # num_kp一般用于指定检测或跟踪关键点的数量,如人脸关键点、手部关键点等,数值大小一般与具体任务相关；
    # image_channel用于指定输入图像的通道数,一般为1或3,分别表示灰度图或RGB图；
    # feature_channel用于指定卷积或特征提取层的输出通道数,一般越大表示特征表达能力越强；
    # estimate_jacobian用于控制是否估计雅各比矩阵,如果设置为True,表示需要计算特征点的空间坐标,
    # 一般在三维重建或位姿估计等任务中会用到.
    num_kp: 15
    image_channel: 3
    feature_channel: 32
    estimate_jacobian: False   # True
  # kp_detector_params一般用于存储关键点检测器的参数配置,这些参数主要用于控制关键点检测器的行为和性能.
  kp_detector_params:
    # temperature:温度参数,用于调节softmax函数输出的概率分布的平滑程度,一般取较小的值可以得到更加尖锐的概率分布,以提高模型的鲁棒性和泛化能力.
    # block_expansion:通道扩展因子,用于控制卷积块中卷积层输出通道数的扩展倍数,以增加模型的容量和表达能力.
    # max_features:特征通道最大数量,用于限制特征通道数的最大值,以避免特征通道数量过多导致计算量过大或过拟合.
    # scale_factor:金字塔缩放因子,用于控制金字塔层数之间的缩放倍数,以增加特征表达的尺度和范围.
    # num_blocks:卷积块数量,用于控制卷积块的数量,以增加模型的深度和复杂度.
    # reshape_channel:特征通道重塑数量,用于将特征图中的空间维度展平并重塑特征通道维度的数量.
    # reshape_depth:特征通道重塑深度,用于控制特征通道重塑后的深度大小,以控制特征图的空间分辨率和通道维度大小.
    temperature: 0.1
    block_expansion: 32
    max_features: 1024
    scale_factor: 0.25         # 0.25
    num_blocks: 5
    reshape_channel: 16384  # 16384 = 1024 * 16
    reshape_depth: 16
  # 控制人体姿态估计器指的是通过调整模型参数、优化算法、改变数据输入等方式,
  # 控制人体姿态估计器的性能和精度,使其能够更好地适应不同的应用场景和需求.
  he_estimator_params:
    # block_expansion:通道扩展因子,用于控制卷积块中卷积层输出通道数的扩展倍数,以增加模型的容量和表达能力.
    # max_features:特征通道最大数量,用于限制特征通道数的最大值,以避免特征通道数量过多导致计算量过大或过拟合.
    # num_bins:关键点数量,用于控制输出的关键点数量,一般和人体姿态的自由度和关键点的数量有关.
    block_expansion: 64
    max_features: 2048
    num_bins: 66
  # generator_params 是指深度学习中的生成器模型参数,主要用于生成对抗网络 (GAN) 中的生成器部分.
  generator_params:
    # block_expansion：表示每个卷积块中卷积核的扩展系数,即在每个卷积块中卷积核的数量是上一层卷积核数量的多少倍.
    # 例如,在该参数中的值为 64 时,表示每个卷积块中的卷积核数量是上一层卷积核数量的 64 倍.
    # max_features：表示生成器网络中最大的卷积核数量,这个值一般是 2 的整数次幂,用于保证每层特征图的维度都是 2 的整数次幂,
    # 这样可以方便地进行上采样和下采样.
    # num_down_blocks：表示生成器网络中下采样操作的数量,也就是 U-Net 网络中的下采样部分.
    # reshape_channel：表示生成器网络中 reshape 操作之后的通道数.
    # reshape_depth：表示生成器网络中 reshape 操作之后的深度,即特征图的高度.
    # num_resblocks：表示生成器网络中残差块的数量,用于增强模型的非线性建模能力.
    # estimate_occlusion_map：表示是否要在生成的姿态图像中估计遮挡区域的掩模.
    block_expansion: 64
    max_features: 512
    num_down_blocks: 2
    reshape_channel: 32
    reshape_depth: 16         # 512 = 32 * 16
    num_resblocks: 6
    estimate_occlusion_map: True
    # dense_motion_params是控制稠密运动估计器的参数.
    dense_motion_params:
      # block_expansion: 控制特征块的通道数,即每个块内特征的维度大小.
      # max_features: 控制特征图的最大通道数.这是为了控制模型的复杂度和计算效率,防止特征图通道数量过大而导致计算资源不足.
      # num_blocks: 控制编码器/解码器中的块数量.每个块都包含一些卷积层,用于处理特征图,并将其传递到下一个块.
      # 更多块意味着更多的层和更高的复杂度,但同时也会增加计算成本.
      # reshape_depth: 将特征图重新塑形的深度.这是为了将特征图压缩成一维向量,以便在解码器中重新构建图像时使用.
      # compress: 压缩因子.这是在将运动向量从稠密运动估计器传递到解码器时使用的,它将运动向量压缩成一个较小的向量,
      # 从而降低计算成本.较小的压缩因子将导致更少的信息损失,但也可能会导致更高的计算成本.
      block_expansion: 32
      max_features: 1024
      num_blocks: 5
      # reshape_channel: 32
      reshape_depth: 16
      compress: 4
  # 用来定义判别器的参数集合
  discriminator_params:
    # scales: 对于多尺度训练,定义每个尺度的倍率,这里只有一个尺度,取值为1.
    # block_expansion: 残差块的输出通道数,即输入通道数的倍数.
    # max_features: 通道数的最大值,超过这个值后输出通道数不再增加.
    # num_blocks: 残差块的数量.
    # sn: 是否使用谱归一化（spectral normalization）,用于稳定训练过程.
    scales: [ 1 ]
    block_expansion: 32
    max_features: 512
    num_blocks: 4
    sn: True # 使用谱归一化

# train_params是一个包含各种训练超参数的字典,用于指定训练过程的各种设置
train_params:
  # num_epochs: 训练的总轮数.
  # num_repeats: 每个轮数训练的迭代次数.每次迭代中,数据集中的一个batch会被输入到模型中进行训练,一个batch中包含多个数据样本.
  # epoch_milestones: 定义学习率调整的时间点,即在训练的哪些轮数中需要调整学习率.默认情况下,只在第180轮调整学习率.
  # lr_generator: 生成器的学习率,即生成器网络参数更新的速率.
  # lr_discriminator: 判别器的学习率,即判别器网络参数更新的速率.
  # lr_kp_detector: 关键点检测器的学习率,即关键点检测器网络参数更新的速率.
  # lr_he_estimator: 人体姿态估计器的学习率,即人体姿态估计器网络参数更新的速率.
  num_epochs: 300
  num_repeats: 75
  epoch_milestones: [ 180, ]
  lr_generator: 2.0e-4
  lr_discriminator: 2.0e-4
  lr_kp_detector: 2.0e-4
  lr_he_estimator: 2.0e-4
  # gan_mode指定了GAN的loss计算方式,可以是"hinge"或"ls"；
  # batch_size是训练时的batch size；
  # scales是输入图片经过金字塔缩放后的尺度系数；
  # checkpoint_freq表示每隔多少个epoch保存一次checkpoint；
  # hopenet_snapshot是头部姿态估计器的预训练模型路径.
  gan_mode: 'hinge'    # hinge or ls
  batch_size: 32
  scales: [ 1, 0.5, 0.25, 0.125 ]
  checkpoint_freq: 10
  hopenet_snapshot: '/zlh/Project/deep-head-pose/checkpoints/hopenet_robust_alpha1.pkl'
  # transform_params是数据增强时使用的参数,其中包含了仿射变换和thin-plate spline(TPS)变换的参数.
  # sigma_affine是仿射变换的参数,表示随机仿射变换的标准差.具体来说,
  # 如果将一个图像的像素坐标乘以一个2x2的随机仿射矩阵,这个参数就决定了这个矩阵元素的随机程度.
  # sigma_tps是TPS变换的参数,表示TPS变换的控制点的偏差.TPS变换是一种非线性变换,
  # 可以更好地捕捉人脸的形变,将控制点从一个位置扰动到另一个位置会使变换产生细微的扰动,这个参数决定了这个偏差的随机程度.
  # points_tps是TPS变换的参数,表示TPS变换的控制点数目.控制点越多,变换的自由度越高,但也会导致更多的计算量.
  transform_params:
    sigma_affine: 0.05
    sigma_tps: 0.005
    points_tps: 5
  # 这些是训练时不同损失的权重,每个损失都有自己的权重,用于平衡每个损失对整个训练过程的贡献.
  loss_weights:
    # generator_gan: 生成器的对抗损失,用于生成器欺骗鉴别器.
    # discriminator_gan: 鉴别器的对抗损失,用于判别真实和虚假样本.
    # feature_matching: 特征匹配损失,用于测量生成图像和真实图像在不同尺度下的特征差异.
    # perceptual: 感知损失,用于测量生成图像和真实图像的语义相似性.
    # equivariance_value: 生成器的等变损失,用于确保生成的姿势估计的值在变换（例如旋转）之后不会改变.
    # equivariance_jacobian: 生成器的等变损失,用于确保生成的姿势估计的雅可比矩阵在变换之后不会改变.
    # keypoint: 用于保持生成的关键点和真实关键点之间的一致性.
    # headpose: 用于保持生成的头部姿态和真实头部姿态之间的一致性.
    # expression: 用于保持生成的面部表情和真实面部表情之间的一致性.
    generator_gan: 1
    discriminator_gan: 1
    feature_matching: [ 10, 10, 10, 10 ]
    perceptual: [ 10, 10, 10, 10, 10 ]
    equivariance_value: 10
    equivariance_jacobian: 0    # 10
    keypoint: 10
    headpose: 20
    expression: 5

# visualizer_params 是可视化参数,用于控制模型训练过程中的可视化输出
visualizer_params:
  # kp_size: 绘制关键点时点的大小,默认为5
  # draw_border: 是否在图片周围绘制边框,默认为True
  # colormap: 绘制热力图的颜色映射,默认为'gist_rainbow'
  kp_size: 5
  draw_border: True
  colormap: 'gist_rainbow'
